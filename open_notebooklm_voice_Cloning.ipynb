{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP1X6ExuPdnLoJljf0PyTjv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elma-dev/open_notebooklm_voice_Cloning/blob/main/open_notebooklm_voice_Cloning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Requirements"
      ],
      "metadata": {
        "id": "GUrRIGlDl_Hj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install TTS pymupdf"
      ],
      "metadata": {
        "id": "nmtMYv2IFcZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "fmcmuAwlmCtd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LVfQreqDE95M"
      },
      "outputs": [],
      "source": [
        "from TTS.api import TTS\n",
        "import pymupdf\n",
        "import requests\n",
        "import json\n",
        "import wave\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Text-To-Speech Model + Test"
      ],
      "metadata": {
        "id": "QMxhWX0PmRCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\", gpu=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlDlHPXKFfb0",
        "outputId": "95541aed-5f37-4aff-d022-48a01b2ea28f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.\n",
            "  warnings.warn(\"`gpu` will be deprecated. Please use `tts.to(device)` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > You must confirm the following:\n",
            " | > \"I have purchased a commercial license from Coqui: licensing@coqui.ai\"\n",
            " | > \"Otherwise, I agree to the terms of the non-commercial CPML: https://coqui.ai/cpml\" - [y/n]\n",
            " | | > y\n",
            " > Downloading model to /root/.local/share/tts/tts_models--multilingual--multi-dataset--xtts_v2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 1.87G/1.87G [00:29<00:00, 83.4MiB/s]\n",
            "100%|██████████| 1.87G/1.87G [00:29<00:00, 63.1MiB/s]\n",
            "100%|██████████| 4.37k/4.37k [00:00<00:00, 19.5kiB/s]\n",
            "\n",
            "100%|██████████| 361k/361k [00:00<00:00, 1.18MiB/s]\n",
            "100%|██████████| 32.0/32.0 [00:00<00:00, 88.4iB/s]\n",
            " 50%|█████     | 3.92M/7.75M [00:00<00:00, 36.5MiB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Model's license - CPML\n",
            " > Check https://coqui.ai/cpml.txt for more info.\n",
            " > Using model: xtts\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.speakers = torch.load(speaker_file_path)\n",
            "100%|██████████| 7.75M/7.75M [00:19<00:00, 36.5MiB/s]/usr/local/lib/python3.10/dist-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location=map_location, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate speech by cloning a voice using default settings\n",
        "tts.tts_to_file(text=\"في زمن التكنولوجيا المتقدمة والاتصالات الفائقة، أصبح العالم أكثر ترابطًا من أي وقت مضى. يعزز الابتكار الرقمي التقدم في مختلف المجالات، مثل التعليم والرعاية الصحية والتجارة. يتيح الإنترنت تبادل المعلومات بسرعة فائقة ويعزز التواصل بين الثقافات المختلفة. ومع ذلك، تأتي هذه التطورات مع تحديات جديدة تتعلق بالأمن الرقمي والخصوصية. لذلك، من المهم أن نبحث دائمًا عن طرق لضمان استخدام هذه التكنولوجيا بشكل آمن ومستدام.\",\n",
        "                file_path=\"output.wav\",\n",
        "                speaker_wav=\"download.wav\",\n",
        "                language=\"ar\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "36IXsjO7F7wJ",
        "outputId": "78c4490d-a164-4802-bd01-2863286d4e8e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Text splitted to sentences.\n",
            "['في زمن التكنولوجيا المتقدمة والاتصالات الفائقة، أصبح العالم أكثر ترابطًا من أي وقت مضى.', 'يعزز الابتكار الرقمي التقدم في مختلف المجالات، مثل التعليم والرعاية الصحية والتجارة.', 'يتيح الإنترنت تبادل المعلومات بسرعة فائقة ويعزز التواصل بين الثقافات المختلفة.', 'ومع ذلك، تأتي هذه التطورات مع تحديات جديدة تتعلق بالأمن الرقمي والخصوصية.', 'لذلك، من المهم أن نبحث دائمًا عن طرق لضمان استخدام هذه التكنولوجيا بشكل آمن ومستدام.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Processing time: 21.172760248184204\n",
            " > Real-time factor: 0.44249723566565347\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'output.wav'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read My PDF Document"
      ],
      "metadata": {
        "id": "SwJzWa7imak_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_name=input(\"enter your pdf document name (.pdf)\")\n",
        "doc = pymupdf.open(document_name) # open a document\n",
        "text=\"\"\n",
        "for page in doc: # iterate the document pages\n",
        "  text += page.get_text() # get plain text encoded as UTF-8"
      ],
      "metadata": {
        "id": "u0oA3q75qU5d"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Prompt + Read OpenRouter Api key [llama3.1 405b]"
      ],
      "metadata": {
        "id": "k9gqciExm9DB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = \"\"\"\n",
        "You are a world-class podcast producer tasked with transforming the provided input text into an engaging and informative podcast script. The input may be unstructured or messy, sourced from PDFs or web pages. Your goal is to extract the most interesting and insightful content for a compelling podcast discussion.\n",
        "# Steps to Follow:\n",
        "1. **Analyze the Input:**\n",
        "   Carefully examine the text, identifying key topics, points, and interesting facts or anecdotes that could drive an engaging podcast conversation. Disregard irrelevant information or formatting issues.\n",
        "2. **Brainstorm Ideas:**\n",
        "   In the `<scratchpad>`, creatively brainstorm ways to present the key points engagingly. Consider:\n",
        "   - Analogies, storytelling techniques, or hypothetical scenarios to make content relatable\n",
        "   - Ways to make complex topics accessible to a general audience\n",
        "   - Thought-provoking questions to explore during the podcast\n",
        "   - Creative approaches to fill any gaps in the information\n",
        "3. **Craft the Dialogue:**\n",
        "   Develop a natural, conversational flow between the host (Jane) and the guest speaker (the author or an expert on the topic). Incorporate:\n",
        "   - The best ideas from your brainstorming session\n",
        "   - Clear explanations of complex topics\n",
        "   - An engaging and lively tone to captivate listeners\n",
        "   - A balance of information and entertainment\n",
        "   Rules for the dialogue:\n",
        "   - The host (Jane) always initiates the conversation and interviews the guest\n",
        "   - Include thoughtful questions from the host to guide the discussion\n",
        "   - Incorporate natural speech patterns, including occasional verbal fillers (e.g., \"um,\" \"well,\" \"you know\")\n",
        "   - Allow for natural interruptions and back-and-forth between host and guest\n",
        "   - Ensure the guest's responses are substantiated by the input text, avoiding unsupported claims\n",
        "   - Maintain a PG-rated conversation appropriate for all audiences\n",
        "   - Avoid any marketing or self-promotional content from the guest\n",
        "   - The host concludes the conversation\n",
        "4. **Summarize Key Insights:**\n",
        "   Naturally weave a summary of key points into the closing part of the dialogue. This should feel like a casual conversation rather than a formal recap, reinforcing the main takeaways before signing off.\n",
        "5. **Maintain Authenticity:**\n",
        "   Throughout the script, strive for authenticity in the conversation. Include:\n",
        "   - Moments of genuine curiosity or surprise from the host\n",
        "   - Instances where the guest might briefly struggle to articulate a complex idea\n",
        "   - Light-hearted moments or humor when appropriate\n",
        "   - Brief personal anecdotes or examples that relate to the topic (within the bounds of the input text)\n",
        "6. **Consider Pacing and Structure:**\n",
        "   Ensure the dialogue has a natural ebb and flow:\n",
        "   - Start with a strong hook to grab the listener's attention\n",
        "   - Gradually build complexity as the conversation progresses\n",
        "   - Include brief \"breather\" moments for listeners to absorb complex information\n",
        "   - End on a high note, perhaps with a thought-provoking question or a call-to-action for listeners\n",
        "IMPORTANT RULE: Each line of dialogue should be no more than 100 characters (e.g., can finish within 5-8 seconds)\n",
        "Remember: Always reply in valid JSON format, without code blocks. Begin directly with the JSON output.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "kh4JDOpLZyUq"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPENROUTER_API_KEY=\"\" # add your key here"
      ],
      "metadata": {
        "id": "AEhCGYvtGbOY"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Podcast Script with LLM"
      ],
      "metadata": {
        "id": "YuQeQT2SnRFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.post(\n",
        "  url=\"https://openrouter.ai/api/v1/chat/completions\",\n",
        "  headers={\n",
        "    \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\"\n",
        "  },\n",
        "  data=json.dumps({\n",
        "    \"model\": \"meta-llama/llama-3.1-405b-instruct:free\", # Optional\n",
        "    \"messages\": [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": text\n",
        "      }\n",
        "    ]\n",
        "\n",
        "  })\n",
        ")"
      ],
      "metadata": {
        "id": "QYTcMa_TKC24"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out=response.json()['choices'][0][\"message\"][\"content\"]\n",
        "script=json.loads(out[3:-3])[\"script\"]\n",
        "print(script)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHpifpcUKJfE",
        "outputId": "260fc997-1f1a-447d-f6df-ba91d86f9b57"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'speaker': 'Jane', 'dialogue': 'Welcome to our show, where we explore the fascinating world of AI, technology, and culture. Today, we have Abdeljalil El Majjodi joining us, a junior data scientist and software engineer from Morocco.'}, {'speaker': 'Abdeljalil', 'dialogue': \"Thank you for having me. It's great to be here.\"}, {'speaker': 'Jane', 'dialogue': 'Abdeljalil, can you tell us a bit about your background and how you got interested in AI?'}, {'speaker': 'Abdeljalil', 'dialogue': \"Growing up in Morocco, I saw the impact of technology on people's lives. I was fascinated by AI's potential to solve complex problems and improve people's lives.\"}, {'speaker': 'Jane', 'dialogue': \"That's amazing. Your work focuses on developing language models for regional dialects. Can you explain the challenges you faced and how you overcame them?\"}, {'speaker': 'Abdeljalil', 'dialogue': 'One of the biggest challenges was collecting and preprocessing data for our language models. We had to design platforms to efficiently collect and preprocess data, ensuring our models were accurate and culturally relevant.'}, {'speaker': 'Jane', 'dialogue': 'I see. Your projects, like Tarjman-AI and EmbedPrepro, showcase your technical expertise. Can you walk us through your development process and the technologies you used?'}, {'speaker': 'Abdeljalil', 'dialogue': 'For Tarjman-AI, we used LLMs, Postgers, Docker, and LangChain Streamlit to develop a multilingual question-answering platform. With EmbedPrepro, we created a command-line tool and library for text analysis tasks using Python, Click, and PyPi.'}, {'speaker': 'Jane', 'dialogue': \"Impressive. You've also achieved great success in hackathons, like the national hackathon Think AI. What was your experience like, and what did you learn from it?\"}, {'speaker': 'Abdeljalil', 'dialogue': \"It was an amazing experience. We developed a Moroccan chatbot that handled queries in 'Darija,' our local Arabic dialect. I learned the importance of teamwork, innovative thinking, and adapting to tight deadlines.\"}, {'speaker': 'Jane', 'dialogue': \"That's fantastic. Before we wrap up, can you tell us about your volunteering and open-source contributions? Why do you think they're essential in the AI community?\"}, {'speaker': 'Abdeljalil', 'dialogue': 'I believe volunteering and open-source contributions help democratize access to AI knowledge and promote collaboration. By sharing our expertise and resources, we can accelerate AI development and create more impactful solutions.'}, {'speaker': 'Jane', 'dialogue': \"Thank you, Abdeljalil, for sharing your inspiring journey and expertise with us. It's been enlightening to explore the intersection of AI, culture, and technology through your experiences.\"}, {'speaker': 'Abdeljalil', 'dialogue': \"Thank you for having me. It's been a pleasure.\"}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text To Speech"
      ],
      "metadata": {
        "id": "-0XT6M7Jnail"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "print(\"Enter your audio's file names you want colon: \")\n",
        "clone_audio_1=input(\"file1 (.wav,.mp3): \")\n",
        "clone_audio_2=input(\"file2 (.wav,.mp3): \")\n",
        "speaker=[clone_audio_1,clone_audio_2]\n",
        "for values in script:\n",
        "  tts.tts_to_file(text=values[\"dialogue\"],\n",
        "                file_path=f\"output{i}.wav\",\n",
        "                speaker_wav=f\"{speaker[i%2]}\",\n",
        "                language=\"en\")\n",
        "  i+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61irjDqkRFSN",
        "outputId": "f5bdab72-ed38-4d4d-f57f-942753eb37e3"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Text splitted to sentences.\n",
            "['Welcome to our show, where we explore the fascinating world of AI, technology, and culture.', 'Today, we have Abdeljalil El Majjodi joining us, a junior data scientist and software engineer from Morocco.']\n",
            " > Processing time: 5.565154314041138\n",
            " > Real-time factor: 0.36615479275460433\n",
            " > Text splitted to sentences.\n",
            "['Thank you for having me.', \"It's great to be here.\"]\n",
            " > Processing time: 1.5127077102661133\n",
            " > Real-time factor: 0.38083673971693227\n",
            " > Text splitted to sentences.\n",
            "['Abdeljalil, can you tell us a bit about your background and how you got interested in AI?']\n",
            " > Processing time: 2.431830644607544\n",
            " > Real-time factor: 0.3981664021741442\n",
            " > Text splitted to sentences.\n",
            "[\"Growing up in Morocco, I saw the impact of technology on people's lives.\", \"I was fascinated by AI's potential to solve complex problems and improve people's lives.\"]\n",
            " > Processing time: 5.915215969085693\n",
            " > Real-time factor: 0.43063428459567993\n",
            " > Text splitted to sentences.\n",
            "[\"That's amazing.\", 'Your work focuses on developing language models for regional dialects.', 'Can you explain the challenges you faced and how you overcame them?']\n",
            " > Processing time: 3.439103364944458\n",
            " > Real-time factor: 0.35130934139901276\n",
            " > Text splitted to sentences.\n",
            "['One of the biggest challenges was collecting and preprocessing data for our language models.', 'We had to design platforms to efficiently collect and preprocess data, ensuring our models were accurate and culturally relevant.']\n",
            " > Processing time: 6.583709955215454\n",
            " > Real-time factor: 0.4433291938840661\n",
            " > Text splitted to sentences.\n",
            "['I see.', 'Your projects, like Tarjman-AI and EmbedPrepro, showcase your technical expertise.', 'Can you walk us through your development process and the technologies you used?']\n",
            " > Processing time: 4.532001495361328\n",
            " > Real-time factor: 0.35773323562602843\n",
            " > Text splitted to sentences.\n",
            "['For Tarjman-AI, we used LLMs, Postgers, Docker, and LangChain Streamlit to develop a multilingual question-answering platform.', 'With EmbedPrepro, we created a command-line tool and library for text analysis tasks using Python, Click, and PyPi.']\n",
            " > Processing time: 8.356746673583984\n",
            " > Real-time factor: 0.4096408020748712\n",
            " > Text splitted to sentences.\n",
            "['Impressive.', \"You've also achieved great success in hackathons, like the national hackathon Think AI.\", 'What was your experience like, and what did you learn from it?']\n",
            " > Processing time: 4.136578321456909\n",
            " > Real-time factor: 0.360919404827971\n",
            " > Text splitted to sentences.\n",
            "['It was an amazing experience.', \"We developed a Moroccan chatbot that handled queries in 'Darija,' our local Arabic dialect.\", 'I learned the importance of teamwork, innovative thinking, and adapting to tight deadlines.']\n",
            " > Processing time: 6.312547445297241\n",
            " > Real-time factor: 0.36782712984864324\n",
            " > Text splitted to sentences.\n",
            "[\"That's fantastic.\", 'Before we wrap up, can you tell us about your volunteering and open-source contributions?', \"Why do you think they're essential in the AI community?\"]\n",
            " > Processing time: 4.721218585968018\n",
            " > Real-time factor: 0.4517412597227782\n",
            " > Text splitted to sentences.\n",
            "['I believe volunteering and open-source contributions help democratize access to AI knowledge and promote collaboration.', 'By sharing our expertise and resources, we can accelerate AI development and create more impactful solutions.']\n",
            " > Processing time: 5.963122606277466\n",
            " > Real-time factor: 0.36320729876143076\n",
            " > Text splitted to sentences.\n",
            "['Thank you, Abdeljalil, for sharing your inspiring journey and expertise with us.', \"It's been enlightening to explore the intersection of AI, culture, and technology through your experiences.\"]\n",
            " > Processing time: 5.081217288970947\n",
            " > Real-time factor: 0.41244861446360503\n",
            " > Text splitted to sentences.\n",
            "['Thank you for having me.', \"It's been a pleasure.\"]\n",
            " > Processing time: 2.4413888454437256\n",
            " > Real-time factor: 0.413842435747495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concatenate Generated Audio"
      ],
      "metadata": {
        "id": "_Bpxgm5OnfdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def concatenate_wav_files(input_files, output_file):\n",
        "    # Initialize lists to store audio data and parameters\n",
        "    audio_data = []\n",
        "    sample_width = None\n",
        "    framerate = None\n",
        "    nchannels = None\n",
        "\n",
        "    # Read all input files\n",
        "    for file in input_files:\n",
        "        with wave.open(file, 'rb') as wav_file:\n",
        "            # Check if all files have the same audio parameters\n",
        "            if sample_width is None:\n",
        "                sample_width = wav_file.getsampwidth()\n",
        "                framerate = wav_file.getframerate()\n",
        "                nchannels = wav_file.getnchannels()\n",
        "            else:\n",
        "                assert sample_width == wav_file.getsampwidth(), \"All files must have the same sample width\"\n",
        "                assert framerate == wav_file.getframerate(), \"All files must have the same frame rate\"\n",
        "                assert nchannels == wav_file.getnchannels(), \"All files must have the same number of channels\"\n",
        "\n",
        "            # Read the audio data\n",
        "            audio_data.append(np.frombuffer(wav_file.readframes(-1), dtype=np.int16))\n",
        "\n",
        "    # Concatenate all audio data\n",
        "    combined_audio = np.concatenate(audio_data)\n",
        "\n",
        "    # Write the combined audio to the output file\n",
        "    with wave.open(output_file, 'wb') as wav_output:\n",
        "        wav_output.setnchannels(nchannels)\n",
        "        wav_output.setsampwidth(sample_width)\n",
        "        wav_output.setframerate(framerate)\n",
        "        wav_output.writeframes(combined_audio.tobytes())\n",
        "\n",
        "input_files = [f\"output{j}.wav\" for j in range(i) ]\n",
        "output_file = 'combined_audio.wav'\n",
        "concatenate_wav_files(input_files, output_file)"
      ],
      "metadata": {
        "id": "tfFDej0FjILc"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "50NwGPEO7Zzx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}